{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import config\n",
    "from utils import (\n",
    "    get_model_object_detector,\n",
    "    collate_fn,\n",
    "    get_transform,\n",
    "    myOwnDataset,\n",
    "    save_model,\n",
    ")\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.05s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "my_dataset = myOwnDataset(\n",
    "    root=config.train_data_dir, annotation=config.train_coco, transforms=get_transform()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x7f9fd844a4a0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_loader = torch.utils.data.DataLoader(\n",
    "    my_dataset,\n",
    "    batch_size=config.train_batch_size,\n",
    "    shuffle=config.train_shuffle_dl,\n",
    "    num_workers=config.num_workers_dl,\n",
    "    collate_fn=collate_fn,\n",
    ")\n",
    "data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select device (whether GPU or CPU)\n",
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for imgs, annotations in data_loader:\n",
    "    if len(annotations[0]['boxes']) == 0:\n",
    "        continue\n",
    "\n",
    "    imgs = list(img.to(device) for img in imgs)\n",
    "    annotations = [{k: v.to(device) for k, v in t.items()} for t in annotations]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/billy/.local/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/billy/.local/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=FasterRCNN_ResNet50_FPN_Weights.COCO_V1`. You can also use `weights=FasterRCNN_ResNet50_FPN_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "FasterRCNN(\n",
       "  (transform): GeneralizedRCNNTransform(\n",
       "      Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
       "      Resize(min_size=(800,), max_size=1333, mode='bilinear')\n",
       "  )\n",
       "  (backbone): BackboneWithFPN(\n",
       "    (body): IntermediateLayerGetter(\n",
       "      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "      (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "      (layer1): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer2): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer3): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (4): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (5): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer4): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): FrozenBatchNorm2d(2048, eps=0.0)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (fpn): FeaturePyramidNetwork(\n",
       "      (inner_blocks): ModuleList(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (2): Conv2dNormActivation(\n",
       "          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (3): Conv2dNormActivation(\n",
       "          (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (layer_blocks): ModuleList(\n",
       "        (0-3): 4 x Conv2dNormActivation(\n",
       "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (extra_blocks): LastLevelMaxPool()\n",
       "    )\n",
       "  )\n",
       "  (rpn): RegionProposalNetwork(\n",
       "    (anchor_generator): AnchorGenerator()\n",
       "    (head): RPNHead(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (cls_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bbox_pred): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (roi_heads): RoIHeads(\n",
       "    (box_roi_pool): MultiScaleRoIAlign(featmap_names=['0', '1', '2', '3'], output_size=(7, 7), sampling_ratio=2)\n",
       "    (box_head): TwoMLPHead(\n",
       "      (fc6): Linear(in_features=12544, out_features=1024, bias=True)\n",
       "      (fc7): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    )\n",
       "    (box_predictor): FastRCNNPredictor(\n",
       "      (cls_score): Linear(in_features=1024, out_features=3, bias=True)\n",
       "      (bbox_pred): Linear(in_features=1024, out_features=12, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_model_object_detector(config.num_classes)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "optimizer = torch.optim.SGD(\n",
    "    params, lr=config.lr, momentum=config.momentum, weight_decay=config.weight_decay\n",
    ")\n",
    "\n",
    "len_dataloader = len(data_loader)\n",
    "\n",
    "Path(\"result/\").mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0/5\n",
      "Iteration: 1/5406, Loss: 1.652025818824768\n",
      "Iteration: 2/5406, Loss: 0.5345838069915771\n",
      "Iteration: 3/5406, Loss: 0.44206321239471436\n",
      "Iteration: 4/5406, Loss: 0.2499985247850418\n",
      "Iteration: 5/5406, Loss: 0.32561054825782776\n",
      "Iteration: 6/5406, Loss: 0.30881208181381226\n",
      "Iteration: 7/5406, Loss: 0.2843503952026367\n",
      "Iteration: 8/5406, Loss: 1.3471219539642334\n",
      "Iteration: 9/5406, Loss: 0.30974382162094116\n",
      "Iteration: 10/5406, Loss: 0.8179190754890442\n",
      "Iteration: 11/5406, Loss: 0.40990716218948364\n",
      "Iteration: 12/5406, Loss: 0.25864091515541077\n",
      "Iteration: 13/5406, Loss: 0.17518705129623413\n",
      "Iteration: 14/5406, Loss: 0.16952385008335114\n",
      "Iteration: 15/5406, Loss: 0.2508592903614044\n",
      "Iteration: 16/5406, Loss: 0.27716881036758423\n",
      "Iteration: 17/5406, Loss: 0.4696740508079529\n",
      "Iteration: 18/5406, Loss: 0.27247685194015503\n",
      "Iteration: 19/5406, Loss: 0.7643455266952515\n",
      "Iteration: 20/5406, Loss: 0.17919102311134338\n",
      "Iteration: 21/5406, Loss: 0.17627660930156708\n",
      "Iteration: 22/5406, Loss: 0.1671677827835083\n",
      "Iteration: 23/5406, Loss: 0.1971295028924942\n",
      "Iteration: 24/5406, Loss: 0.14907099306583405\n",
      "Iteration: 25/5406, Loss: 0.39684465527534485\n",
      "Iteration: 26/5406, Loss: 1.0267280340194702\n",
      "Iteration: 27/5406, Loss: 0.12871764600276947\n",
      "Iteration: 28/5406, Loss: 0.10811110585927963\n",
      "Iteration: 29/5406, Loss: 0.17989180982112885\n",
      "Iteration: 30/5406, Loss: 0.20477811992168427\n",
      "Iteration: 31/5406, Loss: 2.790255069732666\n",
      "Iteration: 32/5406, Loss: 0.2126561999320984\n",
      "Iteration: 33/5406, Loss: 0.7680681943893433\n",
      "Iteration: 34/5406, Loss: 0.5784575343132019\n",
      "Iteration: 35/5406, Loss: 0.1701047271490097\n",
      "Iteration: 36/5406, Loss: 0.510786771774292\n",
      "Iteration: 37/5406, Loss: 0.12858846783638\n",
      "Iteration: 38/5406, Loss: 0.11540544778108597\n",
      "Iteration: 39/5406, Loss: 0.12384634464979172\n",
      "Iteration: 40/5406, Loss: 0.14035235345363617\n",
      "Iteration: 41/5406, Loss: 0.5267380475997925\n",
      "Iteration: 42/5406, Loss: 0.14786891639232635\n",
      "Iteration: 43/5406, Loss: 0.19796815514564514\n",
      "Iteration: 44/5406, Loss: 0.8976320624351501\n",
      "Iteration: 45/5406, Loss: 0.3831702172756195\n",
      "Iteration: 46/5406, Loss: 0.4109351336956024\n",
      "Iteration: 47/5406, Loss: 0.2773972153663635\n",
      "Iteration: 48/5406, Loss: 0.40282511711120605\n",
      "Iteration: 49/5406, Loss: 1.1674710512161255\n",
      "Iteration: 50/5406, Loss: 0.9050716757774353\n",
      "Iteration: 51/5406, Loss: 0.18018049001693726\n",
      "Epoch: 1/5\n",
      "Iteration: 1/5406, Loss: 0.2775077819824219\n",
      "Iteration: 2/5406, Loss: 0.30493244528770447\n",
      "Iteration: 3/5406, Loss: 0.28200986981391907\n",
      "Iteration: 4/5406, Loss: 0.1614474058151245\n",
      "Iteration: 5/5406, Loss: 0.08424817770719528\n",
      "Iteration: 6/5406, Loss: 0.1461840271949768\n",
      "Iteration: 7/5406, Loss: 0.09592434018850327\n",
      "Iteration: 8/5406, Loss: 0.8438510298728943\n",
      "Iteration: 9/5406, Loss: 0.12898926436901093\n",
      "Iteration: 10/5406, Loss: 0.461091011762619\n",
      "Iteration: 11/5406, Loss: 0.29330921173095703\n",
      "Iteration: 12/5406, Loss: 0.14457955956459045\n",
      "Iteration: 13/5406, Loss: 0.1002497747540474\n",
      "Iteration: 14/5406, Loss: 0.08637025207281113\n",
      "Iteration: 15/5406, Loss: 0.10145794600248337\n",
      "Iteration: 16/5406, Loss: 0.1510365754365921\n",
      "Iteration: 17/5406, Loss: 0.1579754650592804\n",
      "Iteration: 18/5406, Loss: 0.13510924577713013\n",
      "Iteration: 19/5406, Loss: 0.4829587936401367\n",
      "Iteration: 20/5406, Loss: 0.0390441007912159\n",
      "Iteration: 21/5406, Loss: 0.12666462361812592\n",
      "Iteration: 22/5406, Loss: 0.04878364875912666\n",
      "Iteration: 23/5406, Loss: 0.09833671897649765\n",
      "Iteration: 24/5406, Loss: 0.09878641366958618\n",
      "Iteration: 25/5406, Loss: 0.18862126767635345\n",
      "Iteration: 26/5406, Loss: 0.7399576902389526\n",
      "Iteration: 27/5406, Loss: 0.09061206877231598\n",
      "Iteration: 28/5406, Loss: 0.05416133254766464\n",
      "Iteration: 29/5406, Loss: 0.06970576196908951\n",
      "Iteration: 30/5406, Loss: 0.10306628048419952\n",
      "Iteration: 31/5406, Loss: 0.8483858108520508\n",
      "Iteration: 32/5406, Loss: 0.1382758915424347\n",
      "Iteration: 33/5406, Loss: 0.18172024190425873\n",
      "Iteration: 34/5406, Loss: 0.43139466643333435\n",
      "Iteration: 35/5406, Loss: 0.1607377976179123\n",
      "Iteration: 36/5406, Loss: 0.42721638083457947\n",
      "Iteration: 37/5406, Loss: 0.08410590142011642\n",
      "Iteration: 38/5406, Loss: 0.06713901460170746\n",
      "Iteration: 39/5406, Loss: 0.13329824805259705\n",
      "Iteration: 40/5406, Loss: 0.1204776018857956\n",
      "Iteration: 41/5406, Loss: 0.5886163711547852\n",
      "Iteration: 42/5406, Loss: 0.10614146292209625\n",
      "Iteration: 43/5406, Loss: 0.0990581214427948\n",
      "Iteration: 44/5406, Loss: 0.5641553401947021\n",
      "Iteration: 45/5406, Loss: 0.296554833650589\n",
      "Iteration: 46/5406, Loss: 0.40923547744750977\n",
      "Iteration: 47/5406, Loss: 0.17892107367515564\n",
      "Iteration: 48/5406, Loss: 0.42492642998695374\n",
      "Iteration: 49/5406, Loss: 0.4812895655632019\n",
      "Iteration: 50/5406, Loss: 0.7975141406059265\n",
      "Iteration: 51/5406, Loss: 0.08307400345802307\n",
      "Epoch: 2/5\n",
      "Iteration: 1/5406, Loss: 0.17496927082538605\n",
      "Iteration: 2/5406, Loss: 0.26967236399650574\n",
      "Iteration: 3/5406, Loss: 0.3823074698448181\n",
      "Iteration: 4/5406, Loss: 0.10983917117118835\n",
      "Iteration: 5/5406, Loss: 0.0870957300066948\n",
      "Iteration: 6/5406, Loss: 0.1301213949918747\n",
      "Iteration: 7/5406, Loss: 0.07040946930646896\n",
      "Iteration: 8/5406, Loss: 0.6503927111625671\n",
      "Iteration: 9/5406, Loss: 0.1198834776878357\n",
      "Iteration: 10/5406, Loss: 0.45733341574668884\n",
      "Iteration: 11/5406, Loss: 0.21205690503120422\n",
      "Iteration: 12/5406, Loss: 0.12052435427904129\n",
      "Iteration: 13/5406, Loss: 0.09580628573894501\n",
      "Iteration: 14/5406, Loss: 0.05067132040858269\n",
      "Iteration: 15/5406, Loss: 0.12733377516269684\n",
      "Iteration: 16/5406, Loss: 0.07337304204702377\n",
      "Iteration: 17/5406, Loss: 0.1365957409143448\n",
      "Iteration: 18/5406, Loss: 0.13940665125846863\n",
      "Iteration: 19/5406, Loss: 0.5064283609390259\n",
      "Iteration: 20/5406, Loss: 0.041402243077754974\n",
      "Iteration: 21/5406, Loss: 0.12384048104286194\n",
      "Iteration: 22/5406, Loss: 0.07751326262950897\n",
      "Iteration: 23/5406, Loss: 0.10027394443750381\n",
      "Iteration: 24/5406, Loss: 0.11708986759185791\n",
      "Iteration: 25/5406, Loss: 0.11511505395174026\n",
      "Iteration: 26/5406, Loss: 0.6437436938285828\n",
      "Iteration: 27/5406, Loss: 0.05183308571577072\n",
      "Iteration: 28/5406, Loss: 0.05053027719259262\n",
      "Iteration: 29/5406, Loss: 0.05676315724849701\n",
      "Iteration: 30/5406, Loss: 0.15372061729431152\n",
      "Iteration: 31/5406, Loss: 0.8097697496414185\n",
      "Iteration: 32/5406, Loss: 0.11340641975402832\n",
      "Iteration: 33/5406, Loss: 0.20482668280601501\n",
      "Iteration: 34/5406, Loss: 0.37676435708999634\n",
      "Iteration: 35/5406, Loss: 0.16347074508666992\n",
      "Iteration: 36/5406, Loss: 0.37864285707473755\n",
      "Iteration: 37/5406, Loss: 0.05550111085176468\n",
      "Iteration: 38/5406, Loss: 0.06283479183912277\n",
      "Iteration: 39/5406, Loss: 0.050780631601810455\n",
      "Iteration: 40/5406, Loss: 0.09883451461791992\n",
      "Iteration: 41/5406, Loss: 0.5899177193641663\n",
      "Iteration: 42/5406, Loss: 0.09614071995019913\n",
      "Iteration: 43/5406, Loss: 0.058091338723897934\n",
      "Iteration: 44/5406, Loss: 0.6131654977798462\n",
      "Iteration: 45/5406, Loss: 0.2502175271511078\n",
      "Iteration: 46/5406, Loss: 0.36915916204452515\n",
      "Iteration: 47/5406, Loss: 0.1344062089920044\n",
      "Iteration: 48/5406, Loss: 0.45930227637290955\n",
      "Iteration: 49/5406, Loss: 0.3904176354408264\n",
      "Iteration: 50/5406, Loss: 0.6596327424049377\n",
      "Iteration: 51/5406, Loss: 0.06158236414194107\n",
      "Epoch: 3/5\n",
      "Iteration: 1/5406, Loss: 0.18781480193138123\n",
      "Iteration: 2/5406, Loss: 0.239502415060997\n",
      "Iteration: 3/5406, Loss: 0.3408018946647644\n",
      "Iteration: 4/5406, Loss: 0.11434207111597061\n",
      "Iteration: 5/5406, Loss: 0.1033041775226593\n",
      "Iteration: 6/5406, Loss: 0.08262693136930466\n",
      "Iteration: 7/5406, Loss: 0.055399347096681595\n",
      "Iteration: 8/5406, Loss: 0.6213204860687256\n",
      "Iteration: 9/5406, Loss: 0.07624880969524384\n",
      "Iteration: 10/5406, Loss: 0.435248464345932\n",
      "Iteration: 11/5406, Loss: 0.2120380997657776\n",
      "Iteration: 12/5406, Loss: 0.08750472962856293\n",
      "Iteration: 13/5406, Loss: 0.0755009576678276\n",
      "Iteration: 14/5406, Loss: 0.07461346685886383\n",
      "Iteration: 15/5406, Loss: 0.16102905571460724\n",
      "Iteration: 16/5406, Loss: 0.08501909673213959\n",
      "Iteration: 17/5406, Loss: 0.1399923712015152\n",
      "Iteration: 18/5406, Loss: 0.09807264804840088\n",
      "Iteration: 19/5406, Loss: 0.4025672972202301\n",
      "Iteration: 20/5406, Loss: 0.06798351556062698\n",
      "Iteration: 21/5406, Loss: 0.12326571345329285\n",
      "Iteration: 22/5406, Loss: 0.09831434488296509\n",
      "Iteration: 23/5406, Loss: 0.12418842315673828\n",
      "Iteration: 24/5406, Loss: 0.1728130280971527\n",
      "Iteration: 25/5406, Loss: 0.11913798004388809\n",
      "Iteration: 26/5406, Loss: 0.5605456233024597\n",
      "Iteration: 27/5406, Loss: 0.049207236617803574\n",
      "Iteration: 28/5406, Loss: 0.05622154101729393\n",
      "Iteration: 29/5406, Loss: 0.05494191125035286\n",
      "Iteration: 30/5406, Loss: 0.09333379566669464\n",
      "Iteration: 31/5406, Loss: 1.0219440460205078\n",
      "Iteration: 32/5406, Loss: 0.06211921572685242\n",
      "Iteration: 33/5406, Loss: 0.11327487230300903\n",
      "Iteration: 34/5406, Loss: 0.307083398103714\n",
      "Iteration: 35/5406, Loss: 0.16268792748451233\n",
      "Iteration: 36/5406, Loss: 0.33211764693260193\n",
      "Iteration: 37/5406, Loss: 0.05712181702256203\n",
      "Iteration: 38/5406, Loss: 0.05122038722038269\n",
      "Iteration: 39/5406, Loss: 0.09140948206186295\n",
      "Iteration: 40/5406, Loss: 0.10380598902702332\n",
      "Iteration: 41/5406, Loss: 0.5738129019737244\n",
      "Iteration: 42/5406, Loss: 0.09451495856046677\n",
      "Iteration: 43/5406, Loss: 0.06146450340747833\n",
      "Iteration: 44/5406, Loss: 0.5472446084022522\n",
      "Iteration: 45/5406, Loss: 0.16655507683753967\n",
      "Iteration: 46/5406, Loss: 0.2857178747653961\n",
      "Iteration: 47/5406, Loss: 0.11170926690101624\n",
      "Iteration: 48/5406, Loss: 0.30273714661598206\n",
      "Iteration: 49/5406, Loss: 0.3879544138908386\n",
      "Iteration: 50/5406, Loss: 0.595271110534668\n",
      "Iteration: 51/5406, Loss: 0.06335171312093735\n",
      "Epoch: 4/5\n",
      "Iteration: 1/5406, Loss: 0.14334145188331604\n",
      "Iteration: 2/5406, Loss: 0.165011927485466\n",
      "Iteration: 3/5406, Loss: 0.31804990768432617\n",
      "Iteration: 4/5406, Loss: 0.12018369138240814\n",
      "Iteration: 5/5406, Loss: 0.04866556450724602\n",
      "Iteration: 6/5406, Loss: 0.13658083975315094\n",
      "Iteration: 7/5406, Loss: 0.07131914794445038\n",
      "Iteration: 8/5406, Loss: 0.5552722215652466\n",
      "Iteration: 9/5406, Loss: 0.06943371891975403\n",
      "Iteration: 10/5406, Loss: 0.35696473717689514\n",
      "Iteration: 11/5406, Loss: 0.19578175246715546\n",
      "Iteration: 12/5406, Loss: 0.044905733317136765\n",
      "Iteration: 13/5406, Loss: 0.05343010649085045\n",
      "Iteration: 14/5406, Loss: 0.0523771196603775\n",
      "Iteration: 15/5406, Loss: 0.12616504728794098\n",
      "Iteration: 16/5406, Loss: 0.06740383058786392\n",
      "Iteration: 17/5406, Loss: 0.09174100309610367\n",
      "Iteration: 18/5406, Loss: 0.0673593133687973\n",
      "Iteration: 19/5406, Loss: 0.3022317886352539\n",
      "Iteration: 20/5406, Loss: 0.04151308909058571\n",
      "Iteration: 21/5406, Loss: 0.07068304717540741\n",
      "Iteration: 22/5406, Loss: 0.06611790508031845\n",
      "Iteration: 23/5406, Loss: 0.08170520514249802\n",
      "Iteration: 24/5406, Loss: 0.13062675297260284\n",
      "Iteration: 25/5406, Loss: 0.15155811607837677\n",
      "Iteration: 26/5406, Loss: 0.4650512933731079\n",
      "Iteration: 27/5406, Loss: 0.0431615486741066\n",
      "Iteration: 28/5406, Loss: 0.030291415750980377\n",
      "Iteration: 29/5406, Loss: 0.05105684697628021\n",
      "Iteration: 30/5406, Loss: 0.07733654975891113\n",
      "Iteration: 31/5406, Loss: 0.6738259196281433\n",
      "Iteration: 32/5406, Loss: 0.064735047519207\n",
      "Iteration: 33/5406, Loss: 0.06881114095449448\n",
      "Iteration: 34/5406, Loss: 0.24676550924777985\n",
      "Iteration: 35/5406, Loss: 0.12148351967334747\n",
      "Iteration: 36/5406, Loss: 0.24204087257385254\n",
      "Iteration: 37/5406, Loss: 0.03360050544142723\n",
      "Iteration: 38/5406, Loss: 0.04049888253211975\n",
      "Iteration: 39/5406, Loss: 0.0703362375497818\n",
      "Iteration: 40/5406, Loss: 0.0982789620757103\n",
      "Iteration: 41/5406, Loss: 0.5447329878807068\n",
      "Iteration: 42/5406, Loss: 0.07890007644891739\n",
      "Iteration: 43/5406, Loss: 0.08997327834367752\n",
      "Iteration: 44/5406, Loss: 0.38553470373153687\n",
      "Iteration: 45/5406, Loss: 0.15424492955207825\n",
      "Iteration: 46/5406, Loss: 0.2989136874675751\n",
      "Iteration: 47/5406, Loss: 0.0706697404384613\n",
      "Iteration: 48/5406, Loss: 0.3229530155658722\n",
      "Iteration: 49/5406, Loss: 0.3521650433540344\n",
      "Iteration: 50/5406, Loss: 0.5769714117050171\n",
      "Iteration: 51/5406, Loss: 0.04880543425679207\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(config.num_epochs):\n",
    "    print(f\"Epoch: {epoch}/{config.num_epochs}\")\n",
    "    model.train()\n",
    "    i = 0\n",
    "    for imgs, annotations in data_loader:\n",
    "        if i > config.num_images:\n",
    "            break\n",
    "        if len(annotations[0]['boxes']) == 0:\n",
    "            continue\n",
    "\n",
    "        i += 1\n",
    "        imgs = list(img.to(device) for img in imgs)\n",
    "        annotations = [{k: v.to(device) for k, v in t.items()} for t in annotations]\n",
    "        loss_dict = model(imgs, annotations)\n",
    "        losses = sum(loss for loss in loss_dict.values())\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        losses.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        print(f\"Iteration: {i}/{len_dataloader}, Loss: {losses}\")\n",
    "\n",
    "# Save the trained model\n",
    "save_model('small', config.num_epochs, model, optimizer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
