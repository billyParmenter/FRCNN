{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import config\n",
    "from utils import (\n",
    "    get_model_object_detector,\n",
    "    collate_fn,\n",
    "    get_transform,\n",
    "    myOwnDataset,\n",
    "    save_model,\n",
    ")\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.14s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "my_dataset = myOwnDataset(\n",
    "    root=config.train_data_dir, annotation=config.train_coco, transforms=get_transform()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x2e388438b50>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_loader = torch.utils.data.DataLoader(\n",
    "    my_dataset,\n",
    "    batch_size=config.train_batch_size,\n",
    "    shuffle=config.train_shuffle_dl,\n",
    "    num_workers=config.num_workers_dl,\n",
    "    collate_fn=collate_fn,\n",
    ")\n",
    "data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select device (whether GPU or CPU)\n",
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for imgs, annotations in data_loader:\n",
    "    if len(annotations[0]['boxes']) == 0:\n",
    "        continue\n",
    "\n",
    "    imgs = list(img.to(device) for img in imgs)\n",
    "    annotations = [{k: v.to(device) for k, v in t.items()} for t in annotations]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Source\\AI&ML\\FML\\CSCN8010\\venv\\pytorch_cpu\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "d:\\Source\\AI&ML\\FML\\CSCN8010\\venv\\pytorch_cpu\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=FasterRCNN_ResNet50_FPN_Weights.COCO_V1`. You can also use `weights=FasterRCNN_ResNet50_FPN_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/fasterrcnn_resnet50_fpn_coco-258fb6c6.pth\" to C:\\Users\\billy/.cache\\torch\\hub\\checkpoints\\fasterrcnn_resnet50_fpn_coco-258fb6c6.pth\n",
      "100%|██████████| 160M/160M [00:03<00:00, 50.9MB/s] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "FasterRCNN(\n",
       "  (transform): GeneralizedRCNNTransform(\n",
       "      Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
       "      Resize(min_size=(800,), max_size=1333, mode='bilinear')\n",
       "  )\n",
       "  (backbone): BackboneWithFPN(\n",
       "    (body): IntermediateLayerGetter(\n",
       "      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "      (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "      (layer1): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer2): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer3): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (4): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (5): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer4): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): FrozenBatchNorm2d(2048, eps=0.0)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (fpn): FeaturePyramidNetwork(\n",
       "      (inner_blocks): ModuleList(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (2): Conv2dNormActivation(\n",
       "          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (3): Conv2dNormActivation(\n",
       "          (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (layer_blocks): ModuleList(\n",
       "        (0-3): 4 x Conv2dNormActivation(\n",
       "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (extra_blocks): LastLevelMaxPool()\n",
       "    )\n",
       "  )\n",
       "  (rpn): RegionProposalNetwork(\n",
       "    (anchor_generator): AnchorGenerator()\n",
       "    (head): RPNHead(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (cls_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bbox_pred): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (roi_heads): RoIHeads(\n",
       "    (box_roi_pool): MultiScaleRoIAlign(featmap_names=['0', '1', '2', '3'], output_size=(7, 7), sampling_ratio=2)\n",
       "    (box_head): TwoMLPHead(\n",
       "      (fc6): Linear(in_features=12544, out_features=1024, bias=True)\n",
       "      (fc7): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    )\n",
       "    (box_predictor): FastRCNNPredictor(\n",
       "      (cls_score): Linear(in_features=1024, out_features=9, bias=True)\n",
       "      (bbox_pred): Linear(in_features=1024, out_features=36, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_model_object_detector(config.num_classes)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "optimizer = torch.optim.SGD(\n",
    "    params, lr=config.lr, momentum=config.momentum, weight_decay=config.weight_decay\n",
    ")\n",
    "\n",
    "len_dataloader = len(data_loader)\n",
    "\n",
    "Path(\"result/\").mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0/5\n",
      "Iteration: 1/320, Loss: 3.7390995025634766\n",
      "Iteration: 2/320, Loss: 2.6616415977478027\n",
      "Iteration: 3/320, Loss: 2.7483763694763184\n",
      "Iteration: 4/320, Loss: 1.6395183801651\n",
      "Iteration: 5/320, Loss: 2.2716922760009766\n",
      "Iteration: 6/320, Loss: 1.8055933713912964\n",
      "Iteration: 7/320, Loss: 1.596710443496704\n",
      "Iteration: 8/320, Loss: 1.7667930126190186\n",
      "Iteration: 9/320, Loss: 1.5801701545715332\n",
      "Iteration: 10/320, Loss: 1.6214178800582886\n",
      "Iteration: 11/320, Loss: 1.6195156574249268\n",
      "Iteration: 12/320, Loss: 1.5077381134033203\n",
      "Iteration: 13/320, Loss: 1.6205227375030518\n",
      "Iteration: 14/320, Loss: 1.4873040914535522\n",
      "Iteration: 15/320, Loss: 1.6825674772262573\n",
      "Iteration: 16/320, Loss: 1.3572944402694702\n",
      "Iteration: 17/320, Loss: 1.5121079683303833\n",
      "Iteration: 18/320, Loss: 1.3428581953048706\n",
      "Iteration: 19/320, Loss: 1.739819884300232\n",
      "Iteration: 20/320, Loss: 1.8016616106033325\n",
      "Iteration: 21/320, Loss: 1.6763185262680054\n",
      "Iteration: 22/320, Loss: 1.4962950944900513\n",
      "Iteration: 23/320, Loss: 1.760193943977356\n",
      "Iteration: 24/320, Loss: 1.4105027914047241\n",
      "Iteration: 25/320, Loss: 1.7801865339279175\n",
      "Iteration: 26/320, Loss: 1.452641248703003\n",
      "Iteration: 27/320, Loss: 1.7581342458724976\n",
      "Iteration: 28/320, Loss: 1.6874185800552368\n",
      "Iteration: 29/320, Loss: 1.626046895980835\n",
      "Iteration: 30/320, Loss: 1.7932407855987549\n",
      "Iteration: 31/320, Loss: 1.2513453960418701\n",
      "Iteration: 32/320, Loss: 1.5124074220657349\n",
      "Iteration: 33/320, Loss: 1.4162060022354126\n",
      "Iteration: 34/320, Loss: 1.5641624927520752\n",
      "Iteration: 35/320, Loss: 1.600886344909668\n",
      "Iteration: 36/320, Loss: 1.0986552238464355\n",
      "Iteration: 37/320, Loss: 1.4778978824615479\n",
      "Iteration: 38/320, Loss: 1.2809699773788452\n",
      "Iteration: 39/320, Loss: 1.4422571659088135\n",
      "Iteration: 40/320, Loss: 1.529982566833496\n",
      "Iteration: 41/320, Loss: 1.1830248832702637\n",
      "Iteration: 42/320, Loss: 1.1871392726898193\n",
      "Iteration: 43/320, Loss: 1.3516387939453125\n",
      "Iteration: 44/320, Loss: 1.1629459857940674\n",
      "Iteration: 45/320, Loss: 1.1902343034744263\n",
      "Iteration: 46/320, Loss: 1.5392131805419922\n",
      "Iteration: 47/320, Loss: 1.0653176307678223\n",
      "Iteration: 48/320, Loss: 1.3147419691085815\n",
      "Iteration: 49/320, Loss: 1.1549760103225708\n",
      "Iteration: 50/320, Loss: 1.1041278839111328\n",
      "Iteration: 51/320, Loss: 1.1796432733535767\n",
      "Epoch: 1/5\n",
      "Iteration: 1/320, Loss: 1.2392523288726807\n",
      "Iteration: 2/320, Loss: 1.1116917133331299\n",
      "Iteration: 3/320, Loss: 1.5257657766342163\n",
      "Iteration: 4/320, Loss: 1.3480815887451172\n",
      "Iteration: 5/320, Loss: 1.4411259889602661\n",
      "Iteration: 6/320, Loss: 1.0697083473205566\n",
      "Iteration: 7/320, Loss: 1.3103899955749512\n",
      "Iteration: 8/320, Loss: 1.275681495666504\n",
      "Iteration: 9/320, Loss: 1.394446849822998\n",
      "Iteration: 10/320, Loss: 1.2660833597183228\n",
      "Iteration: 11/320, Loss: 1.3625975847244263\n",
      "Iteration: 12/320, Loss: 0.935954213142395\n",
      "Iteration: 13/320, Loss: 1.2656593322753906\n",
      "Iteration: 14/320, Loss: 1.2713783979415894\n",
      "Iteration: 15/320, Loss: 1.309792399406433\n",
      "Iteration: 16/320, Loss: 1.1565943956375122\n",
      "Iteration: 17/320, Loss: 1.0989913940429688\n",
      "Iteration: 18/320, Loss: 1.1332069635391235\n",
      "Iteration: 19/320, Loss: 1.4553322792053223\n",
      "Iteration: 20/320, Loss: 1.5853203535079956\n",
      "Iteration: 21/320, Loss: 1.075822353363037\n",
      "Iteration: 22/320, Loss: 1.181534767150879\n",
      "Iteration: 23/320, Loss: 1.271225094795227\n",
      "Iteration: 24/320, Loss: 1.334800124168396\n",
      "Iteration: 25/320, Loss: 1.3611929416656494\n",
      "Iteration: 26/320, Loss: 1.3533270359039307\n",
      "Iteration: 27/320, Loss: 1.3396542072296143\n",
      "Iteration: 28/320, Loss: 1.376306414604187\n",
      "Iteration: 29/320, Loss: 1.3753612041473389\n",
      "Iteration: 30/320, Loss: 1.267357349395752\n",
      "Iteration: 31/320, Loss: 1.1696614027023315\n",
      "Iteration: 32/320, Loss: 1.1299738883972168\n",
      "Iteration: 33/320, Loss: 1.2046854496002197\n",
      "Iteration: 34/320, Loss: 1.2898486852645874\n",
      "Iteration: 35/320, Loss: 1.3908312320709229\n",
      "Iteration: 36/320, Loss: 0.9721096754074097\n",
      "Iteration: 37/320, Loss: 1.2767982482910156\n",
      "Iteration: 38/320, Loss: 1.1016871929168701\n",
      "Iteration: 39/320, Loss: 1.1036829948425293\n",
      "Iteration: 40/320, Loss: 1.3256306648254395\n",
      "Iteration: 41/320, Loss: 1.0743333101272583\n",
      "Iteration: 42/320, Loss: 1.1547975540161133\n",
      "Iteration: 43/320, Loss: 1.0519639253616333\n",
      "Iteration: 44/320, Loss: 1.1445958614349365\n",
      "Iteration: 45/320, Loss: 1.2532023191452026\n",
      "Iteration: 46/320, Loss: 1.2319577932357788\n",
      "Iteration: 47/320, Loss: 0.9690661430358887\n",
      "Iteration: 48/320, Loss: 1.0143814086914062\n",
      "Iteration: 49/320, Loss: 0.9810821413993835\n",
      "Iteration: 50/320, Loss: 1.0101903676986694\n",
      "Iteration: 51/320, Loss: 1.0555481910705566\n",
      "Epoch: 2/5\n",
      "Iteration: 1/320, Loss: 1.0414586067199707\n",
      "Iteration: 2/320, Loss: 1.013980507850647\n",
      "Iteration: 3/320, Loss: 1.3958641290664673\n",
      "Iteration: 4/320, Loss: 1.1768293380737305\n",
      "Iteration: 5/320, Loss: 1.3638120889663696\n",
      "Iteration: 6/320, Loss: 1.1321496963500977\n",
      "Iteration: 7/320, Loss: 1.2255268096923828\n",
      "Iteration: 8/320, Loss: 1.175718069076538\n",
      "Iteration: 9/320, Loss: 1.2785239219665527\n",
      "Iteration: 10/320, Loss: 1.060533881187439\n",
      "Iteration: 11/320, Loss: 1.1671266555786133\n",
      "Iteration: 12/320, Loss: 0.8228534460067749\n",
      "Iteration: 13/320, Loss: 1.1148288249969482\n",
      "Iteration: 14/320, Loss: 1.1021201610565186\n",
      "Iteration: 15/320, Loss: 1.0753333568572998\n",
      "Iteration: 16/320, Loss: 1.084240198135376\n",
      "Iteration: 17/320, Loss: 0.9997345209121704\n",
      "Iteration: 18/320, Loss: 1.1265463829040527\n",
      "Iteration: 19/320, Loss: 1.1684516668319702\n",
      "Iteration: 20/320, Loss: 1.3902019262313843\n",
      "Iteration: 21/320, Loss: 0.9142124652862549\n",
      "Iteration: 22/320, Loss: 1.0623947381973267\n",
      "Iteration: 23/320, Loss: 1.175264596939087\n",
      "Iteration: 24/320, Loss: 1.135254144668579\n",
      "Iteration: 25/320, Loss: 1.3738752603530884\n",
      "Iteration: 26/320, Loss: 1.3534317016601562\n",
      "Iteration: 27/320, Loss: 1.1951580047607422\n",
      "Iteration: 28/320, Loss: 1.3267509937286377\n",
      "Iteration: 29/320, Loss: 1.194332242012024\n",
      "Iteration: 30/320, Loss: 1.2794959545135498\n",
      "Iteration: 31/320, Loss: 1.0008556842803955\n",
      "Iteration: 32/320, Loss: 0.9844645261764526\n",
      "Iteration: 33/320, Loss: 1.099962592124939\n",
      "Iteration: 34/320, Loss: 1.1796461343765259\n",
      "Iteration: 35/320, Loss: 1.1596100330352783\n",
      "Iteration: 36/320, Loss: 0.9121595621109009\n",
      "Iteration: 37/320, Loss: 1.3169656991958618\n",
      "Iteration: 38/320, Loss: 1.1136581897735596\n",
      "Iteration: 39/320, Loss: 0.9027231335639954\n",
      "Iteration: 40/320, Loss: 1.3061970472335815\n",
      "Iteration: 41/320, Loss: 1.006981372833252\n",
      "Iteration: 42/320, Loss: 1.115858793258667\n",
      "Iteration: 43/320, Loss: 0.9159119129180908\n",
      "Iteration: 44/320, Loss: 1.0404313802719116\n",
      "Iteration: 45/320, Loss: 1.2492613792419434\n",
      "Iteration: 46/320, Loss: 0.9921528697013855\n",
      "Iteration: 47/320, Loss: 0.8899343013763428\n",
      "Iteration: 48/320, Loss: 0.9282457828521729\n",
      "Iteration: 49/320, Loss: 1.0669608116149902\n",
      "Iteration: 50/320, Loss: 0.9195955991744995\n",
      "Iteration: 51/320, Loss: 1.1083192825317383\n",
      "Epoch: 3/5\n",
      "Iteration: 1/320, Loss: 0.9426504373550415\n",
      "Iteration: 2/320, Loss: 0.999492347240448\n",
      "Iteration: 3/320, Loss: 1.3813263177871704\n",
      "Iteration: 4/320, Loss: 1.0547893047332764\n",
      "Iteration: 5/320, Loss: 1.320709228515625\n",
      "Iteration: 6/320, Loss: 0.9167547821998596\n",
      "Iteration: 7/320, Loss: 1.050577163696289\n",
      "Iteration: 8/320, Loss: 1.1306402683258057\n",
      "Iteration: 9/320, Loss: 1.1468753814697266\n",
      "Iteration: 10/320, Loss: 0.9614315032958984\n",
      "Iteration: 11/320, Loss: 0.981743574142456\n",
      "Iteration: 12/320, Loss: 0.7159332036972046\n",
      "Iteration: 13/320, Loss: 0.9103268384933472\n",
      "Iteration: 14/320, Loss: 1.0299782752990723\n",
      "Iteration: 15/320, Loss: 1.0525974035263062\n",
      "Iteration: 16/320, Loss: 0.9792224168777466\n",
      "Iteration: 17/320, Loss: 0.8277276158332825\n",
      "Iteration: 18/320, Loss: 1.0003652572631836\n",
      "Iteration: 19/320, Loss: 1.024793028831482\n",
      "Iteration: 20/320, Loss: 1.2387516498565674\n",
      "Iteration: 21/320, Loss: 0.8654755353927612\n",
      "Iteration: 22/320, Loss: 1.0144202709197998\n",
      "Iteration: 23/320, Loss: 1.07563316822052\n",
      "Iteration: 24/320, Loss: 1.0321550369262695\n",
      "Iteration: 25/320, Loss: 1.2131093740463257\n",
      "Iteration: 26/320, Loss: 1.1823923587799072\n",
      "Iteration: 27/320, Loss: 1.1331520080566406\n",
      "Iteration: 28/320, Loss: 1.2774330377578735\n",
      "Iteration: 29/320, Loss: 1.1781336069107056\n",
      "Iteration: 30/320, Loss: 0.9641128778457642\n",
      "Iteration: 31/320, Loss: 0.9919091463088989\n",
      "Iteration: 32/320, Loss: 0.9404525756835938\n",
      "Iteration: 33/320, Loss: 1.042683720588684\n",
      "Iteration: 34/320, Loss: 1.0916131734848022\n",
      "Iteration: 35/320, Loss: 0.9481570720672607\n",
      "Iteration: 36/320, Loss: 0.8366909027099609\n",
      "Iteration: 37/320, Loss: 1.2220220565795898\n",
      "Iteration: 38/320, Loss: 1.0528165102005005\n",
      "Iteration: 39/320, Loss: 0.8181225061416626\n",
      "Iteration: 40/320, Loss: 1.1551933288574219\n",
      "Iteration: 41/320, Loss: 0.9835799932479858\n",
      "Iteration: 42/320, Loss: 1.0468965768814087\n",
      "Iteration: 43/320, Loss: 0.8419174551963806\n",
      "Iteration: 44/320, Loss: 0.9719704389572144\n",
      "Iteration: 45/320, Loss: 1.0460370779037476\n",
      "Iteration: 46/320, Loss: 0.897091269493103\n",
      "Iteration: 47/320, Loss: 0.7831527590751648\n",
      "Iteration: 48/320, Loss: 0.8559470176696777\n",
      "Iteration: 49/320, Loss: 0.8605262041091919\n",
      "Iteration: 50/320, Loss: 0.775684118270874\n",
      "Iteration: 51/320, Loss: 1.0460009574890137\n",
      "Epoch: 4/5\n",
      "Iteration: 1/320, Loss: 0.8799834251403809\n",
      "Iteration: 2/320, Loss: 0.8612399101257324\n",
      "Iteration: 3/320, Loss: 1.258312463760376\n",
      "Iteration: 4/320, Loss: 0.9646173715591431\n",
      "Iteration: 5/320, Loss: 1.212004542350769\n",
      "Iteration: 6/320, Loss: 0.9193823933601379\n",
      "Iteration: 7/320, Loss: 0.970453143119812\n",
      "Iteration: 8/320, Loss: 0.9861785173416138\n",
      "Iteration: 9/320, Loss: 1.163341999053955\n",
      "Iteration: 10/320, Loss: 0.9429450631141663\n",
      "Iteration: 11/320, Loss: 0.909356951713562\n",
      "Iteration: 12/320, Loss: 0.6482143402099609\n",
      "Iteration: 13/320, Loss: 0.9853711724281311\n",
      "Iteration: 14/320, Loss: 0.9424338340759277\n",
      "Iteration: 15/320, Loss: 0.9836950898170471\n",
      "Iteration: 16/320, Loss: 0.9238343834877014\n",
      "Iteration: 17/320, Loss: 0.7122384905815125\n",
      "Iteration: 18/320, Loss: 0.9439365267753601\n",
      "Iteration: 19/320, Loss: 0.908336877822876\n",
      "Iteration: 20/320, Loss: 1.1159027814865112\n",
      "Iteration: 21/320, Loss: 0.7895330190658569\n",
      "Iteration: 22/320, Loss: 0.8749861717224121\n",
      "Iteration: 23/320, Loss: 0.9932207465171814\n",
      "Iteration: 24/320, Loss: 0.999669075012207\n",
      "Iteration: 25/320, Loss: 1.071354866027832\n",
      "Iteration: 26/320, Loss: 1.1233326196670532\n",
      "Iteration: 27/320, Loss: 1.0296776294708252\n",
      "Iteration: 28/320, Loss: 1.2475050687789917\n",
      "Iteration: 29/320, Loss: 1.1007665395736694\n",
      "Iteration: 30/320, Loss: 0.8725545406341553\n",
      "Iteration: 31/320, Loss: 0.941724419593811\n",
      "Iteration: 32/320, Loss: 0.9410577416419983\n",
      "Iteration: 33/320, Loss: 0.978312611579895\n",
      "Iteration: 34/320, Loss: 1.0649493932724\n",
      "Iteration: 35/320, Loss: 0.8737499713897705\n",
      "Iteration: 36/320, Loss: 0.7521623373031616\n",
      "Iteration: 37/320, Loss: 1.1608816385269165\n",
      "Iteration: 38/320, Loss: 1.0345008373260498\n",
      "Iteration: 39/320, Loss: 0.7725464105606079\n",
      "Iteration: 40/320, Loss: 1.0473268032073975\n",
      "Iteration: 41/320, Loss: 0.9101824164390564\n",
      "Iteration: 42/320, Loss: 1.0878779888153076\n",
      "Iteration: 43/320, Loss: 0.8334078788757324\n",
      "Iteration: 44/320, Loss: 0.9984604716300964\n",
      "Iteration: 45/320, Loss: 0.9142085909843445\n",
      "Iteration: 46/320, Loss: 0.8779524564743042\n",
      "Iteration: 47/320, Loss: 0.8628084659576416\n",
      "Iteration: 48/320, Loss: 0.7878931760787964\n",
      "Iteration: 49/320, Loss: 0.8855491280555725\n",
      "Iteration: 50/320, Loss: 0.8054875135421753\n",
      "Iteration: 51/320, Loss: 0.8876439332962036\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(config.num_epochs):\n",
    "    print(f\"Epoch: {epoch}/{config.num_epochs}\")\n",
    "    model.train()\n",
    "    i = 0\n",
    "    for imgs, annotations in data_loader:\n",
    "        if i > config.num_images:\n",
    "            break\n",
    "        if len(annotations[0]['boxes']) == 0:\n",
    "            continue\n",
    "\n",
    "        i += 1\n",
    "        imgs = list(img.to(device) for img in imgs)\n",
    "        annotations = [{k: v.to(device) for k, v in t.items()} for t in annotations]\n",
    "        loss_dict = model(imgs, annotations)\n",
    "        losses = sum(loss for loss in loss_dict.values())\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        losses.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        print(f\"Iteration: {i}/{len_dataloader}, Loss: {losses}\")\n",
    "\n",
    "# Save the trained model\n",
    "save_model('small', config.num_epochs, model, optimizer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_cpu",
   "language": "python",
   "name": "pytorch_cpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
